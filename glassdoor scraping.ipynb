{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import copy\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function helps to find all full time jobs searched by the key words we entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_jobs(url, num_jobs):    \n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "\n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=\"D:/chromedriver/chromedriver.exe\", options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//li[contains(@class, 'react-job-listing css-7x0jr eigr9kq3')]\").click()\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//span[contains(@class, 'SVGInline modal_closeIcon')]\").click()  #clicking to the X.\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    while len(jobs) < num_jobs:  #If true, should be still looking for new jobs.\n",
    "\n",
    "        #Let the page load. Change this number based on your internet speed.\n",
    "        #Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "        time.sleep(4)\n",
    "        \n",
    "        # Scrape first job and the rest\n",
    "        first = driver.find_elements_by_xpath(\"//li[contains(@class, 'react-job-listing css-7x0jr eigr9kq3')]\")\n",
    "        \n",
    "        # first job\n",
    "        for f in first:\n",
    "            driver.execute_script(\"arguments[0].click();\", f)\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                company_rate = f.find_element_by_xpath(\".//span[contains(@class, 'css-19pjha7 e1cjmv6j1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company_rate = np.nan      \n",
    "            try:\n",
    "                company = f.find_element_by_xpath(\".//a[contains(@class, 'css-l2wjgv e1n63ojh0 jobLink')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company = np.nan\n",
    "            try:\n",
    "                position = f.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").text\n",
    "            except NoSuchElementException:\n",
    "                position = np.nan      \n",
    "            try:\n",
    "                try:\n",
    "                    location = f.find_element_by_xpath(\".//span[contains(@class, 'pr-xxsm css-1ndif2q e1rrn5ka0')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    location = f.find_element_by_xpath(\".//span[contains(@class, 'css-nq3w9f pr-xxsm css-iii9i8 e1rrn5ka0')]\").text\n",
    "            except NoSuchElementException:\n",
    "                location = np.nan\n",
    "            try:\n",
    "                salary = f.find_element_by_xpath(\".//div[contains(@class, 'css-nq3w9f pr-xxsm')]\").text\n",
    "            except NoSuchElementException:\n",
    "                salary = np.nan    \n",
    "            try:\n",
    "                try:\n",
    "                    status = f.find_element_by_xpath(\".//div[contains(@class, 'css-jcbnij eigr9kq1')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    status = f.find_element_by_xpath(\".//div[contains(@class, 'css-65p68w css-m9i057 css-1uov7ef css-crgfuk eigr9kq1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                status = np.nan\n",
    "            try:\n",
    "                post_date_ago = f.find_element_by_xpath(\".//div[contains(@class, 'd-flex align-items-end pl-std css-mi55ob')]\").text\n",
    "            except NoSuchElementException:\n",
    "                post_date_ago = np.nan\n",
    "            try:\n",
    "                job_url = f.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").get_attribute(\"href\")\n",
    "            except NoSuchElementException:\n",
    "                job_url = np.nan\n",
    "\n",
    "            jobs.append({\"Company Rate\" : company_rate,\n",
    "                    \"Company Name\" : company,\n",
    "                    \"Title\" : position,\n",
    "                    \"Location\" : location,\n",
    "                    \"Salary\" : salary,\n",
    "                    \"Staus\" : status,\n",
    "                    \"Post Date\" : post_date_ago,\n",
    "                    \"Job Link\" : job_url})\n",
    "            \n",
    "        # rest jobs\n",
    "        jl = driver.find_elements_by_xpath(\"//li[contains(@class, 'react-job-listing css-wp148e eigr9kq3')]\")\n",
    "        \n",
    "        for j in tqdm.tqdm(jl):\n",
    "            driver.execute_script(\"arguments[0].click();\", j)\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                company_rate = j.find_element_by_xpath(\".//span[contains(@class, 'css-19pjha7 e1cjmv6j1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company_rate = np.nan\n",
    "            try:\n",
    "                company = j.find_element_by_xpath(\".//a[contains(@class, 'css-l2wjgv e1n63ojh0 jobLink')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company = np.nan\n",
    "            try:\n",
    "                position = j.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").text\n",
    "            except NoSuchElementException:\n",
    "                position = np.nan\n",
    "            try:\n",
    "                try:\n",
    "                    location = j.find_element_by_xpath(\".//span[contains(@class, 'pr-xxsm css-1ndif2q e1rrn5ka0')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    location = j.find_element_by_xpath(\".//span[contains(@class, 'css-nq3w9f pr-xxsm css-iii9i8 e1rrn5ka0')]\").text\n",
    "            except NoSuchElementException:\n",
    "                location = np.nan\n",
    "            try:\n",
    "                salary = j.find_element_by_xpath(\".//div[contains(@class, 'css-nq3w9f pr-xxsm')]\").text\n",
    "            except NoSuchElementException:\n",
    "                salary = np.nan\n",
    "            try:\n",
    "                try:\n",
    "                    status = j.find_element_by_xpath(\".//div[contains(@class, 'css-jcbnij eigr9kq1')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    status = j.find_element_by_xpath(\".//div[contains(@class, 'css-65p68w css-m9i057 css-1uov7ef css-crgfuk eigr9kq1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                status = np.nan\n",
    "            try:\n",
    "                post_date_ago = j.find_element_by_xpath(\".//div[contains(@class, 'd-flex align-items-end pl-std css-mi55ob')]\").text\n",
    "            except NoSuchElementException:\n",
    "                post_date_ago = np.nan\n",
    "            try:\n",
    "                job_url = j.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").get_attribute(\"href\")\n",
    "            except NoSuchElementException:\n",
    "                job_url = np.nan\n",
    "                \n",
    "\n",
    "            jobs.append({\"Company Rate\" : company_rate,\n",
    "                    \"Company Name\" : company,\n",
    "                    \"Title\" : position,\n",
    "                    \"Location\" : location,\n",
    "                    \"Salary\" : salary,\n",
    "                    \"Staus\" : status,\n",
    "                    \"Post Date\" : post_date_ago,\n",
    "                    \"Job Link\" : job_url})\n",
    "\n",
    "            #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\".//li[contains(@class, 'css-1yshuyv e1gri00l3')]\").click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "                \n",
    "    return pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change format of dates\n",
    "today = datetime.today()\n",
    "\n",
    "def check_date_h_d(x):\n",
    "    try:\n",
    "        if(x[-1] == 'h'):\n",
    "            date = int(x[:-1])/24\n",
    "            return str(int(date))+'d'\n",
    "        else:\n",
    "            return x\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def transform_days(x):\n",
    "    try:\n",
    "        x = int(x[:-1])\n",
    "        date = (today - timedelta(days = x)).strftime(\"%d/%m/%Y\")\n",
    "        return date\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_analyst = get_jobs('https://www.glassdoor.com/Job/data-analyst-jobs-SRCH_KO0,12.htm?jobType=fulltime&includeNoSalaryJobs=true&seniorityType=entrylevel', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dates\n",
    "data_analyst['Post Date'] = data_analyst['Post Date'].apply(lambda x: check_date_h_d(x))\n",
    "data_analyst['Post Date'] = data_analyst['Post Date'].apply(lambda x: transform_days(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files\n",
    "csv_data_analyst = copy.copy(data_analyst)\n",
    "csv_data_analyst.to_csv('Glassdoor_data_analyst.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "business_analyst = get_jobs('https://www.glassdoor.com/Job/business-analyst-jobs-SRCH_KO0,16.htm?jobType=fulltime&includeNoSalaryJobs=true&seniorityType=entrylevel', 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_analyst['Post Date'] = business_analyst['Post Date'].apply(lambda x: check_date_h_d(x))\n",
    "business_analyst['Post Date'] = business_analyst['Post Date'].apply(lambda x: transform_days(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_business_analyst = copy.copy(business_analyst)\n",
    "csv_business_analyst.to_csv('Glassdoor_business_analyst.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function helps to find all full time jobs whose titles must have the key words we give"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(url, num_jobs):    \n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "\n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=\"D:/chromedriver/chromedriver.exe\", options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    driver.find_element_by_xpath(\"//strong[contains(@class, 'mr-xxsm')]\").click()\n",
    "    time.sleep(4)\n",
    "    driver.find_element_by_xpath('.//span[@class=\"css-1d8tv35 e16st97e0\"]').click()\n",
    "    driver.find_element_by_xpath('.//li[@value=\"fulltime\"]').click()\n",
    "\n",
    "    #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//li[contains(@class, 'react-job-listing css-7x0jr eigr9kq3')]\").click()\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//span[contains(@class, 'SVGInline modal_closeIcon')]\").click()  #clicking to the X.\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    #Again to click x on job alert\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//li[contains(@class, 'react-job-listing css-7x0jr eigr9kq3')]\").click()\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//span[contains(@class, 'SVGInline modal_closeIcon')]\").click()  #clicking to the X.\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    while len(jobs) < num_jobs:  #If true, should be still looking for new jobs.\n",
    "\n",
    "        #Let the page load. Change this number based on your internet speed.\n",
    "        #Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "        time.sleep(4)\n",
    "        \n",
    "        # Scrape first job and the rest\n",
    "        first = driver.find_elements_by_xpath(\"//li[contains(@class, 'react-job-listing css-7x0jr eigr9kq3')]\")\n",
    "        \n",
    "        # first job\n",
    "        for f in first:\n",
    "            driver.execute_script(\"arguments[0].click();\", f)\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                company_rate = f.find_element_by_xpath(\".//span[contains(@class, 'css-19pjha7 e1cjmv6j1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company_rate = np.nan      \n",
    "            try:\n",
    "                company = f.find_element_by_xpath(\".//a[contains(@class, 'css-l2wjgv e1n63ojh0 jobLink')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company = np.nan\n",
    "            try:\n",
    "                position = f.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").text\n",
    "            except NoSuchElementException:\n",
    "                position = np.nan      \n",
    "            try:\n",
    "                try:\n",
    "                    location = f.find_element_by_xpath(\".//span[contains(@class, 'pr-xxsm css-1ndif2q e1rrn5ka0')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    location = f.find_element_by_xpath(\".//span[contains(@class, 'css-nq3w9f pr-xxsm css-iii9i8 e1rrn5ka0')]\").text\n",
    "            except NoSuchElementException:\n",
    "                location = np.nan\n",
    "            try:\n",
    "                salary = f.find_element_by_xpath(\".//div[contains(@class, 'css-nq3w9f pr-xxsm')]\").text\n",
    "            except NoSuchElementException:\n",
    "                salary = np.nan    \n",
    "            try:\n",
    "                try:\n",
    "                    status = f.find_element_by_xpath(\".//div[contains(@class, 'css-jcbnij eigr9kq1')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    status = f.find_element_by_xpath(\".//div[contains(@class, 'css-65p68w css-m9i057 css-1uov7ef css-crgfuk eigr9kq1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                status = np.nan\n",
    "            try:\n",
    "                post_date_ago = f.find_element_by_xpath(\".//div[contains(@class, 'd-flex align-items-end pl-std css-mi55ob')]\").text\n",
    "            except NoSuchElementException:\n",
    "                post_date_ago = np.nan\n",
    "            try:\n",
    "                job_url = f.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").get_attribute(\"href\")\n",
    "            except NoSuchElementException:\n",
    "                job_url = np.nan\n",
    "\n",
    "            jobs.append({\"Company Rate\" : company_rate,\n",
    "                    \"Company Name\" : company,\n",
    "                    \"Title\" : position,\n",
    "                    \"Location\" : location,\n",
    "                    \"Salary\" : salary,\n",
    "                    \"Staus\" : status,\n",
    "                    \"Post Date\" : post_date_ago,\n",
    "                    \"Job Link\" : job_url})\n",
    "            \n",
    "        # rest jobs\n",
    "        jl = driver.find_elements_by_xpath(\"//li[contains(@class, 'react-job-listing css-wp148e eigr9kq3')]\")\n",
    "        \n",
    "        for j in tqdm.tqdm(jl):\n",
    "            driver.execute_script(\"arguments[0].click();\", j)\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                company_rate = j.find_element_by_xpath(\".//span[contains(@class, 'css-19pjha7 e1cjmv6j1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company_rate = np.nan\n",
    "            try:\n",
    "                company = j.find_element_by_xpath(\".//a[contains(@class, 'css-l2wjgv e1n63ojh0 jobLink')]\").text\n",
    "            except NoSuchElementException:\n",
    "                company = np.nan\n",
    "            try:\n",
    "                position = j.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").text\n",
    "            except NoSuchElementException:\n",
    "                position = np.nan\n",
    "            try:\n",
    "                try:\n",
    "                    location = j.find_element_by_xpath(\".//span[contains(@class, 'pr-xxsm css-1ndif2q e1rrn5ka0')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    location = j.find_element_by_xpath(\".//span[contains(@class, 'css-nq3w9f pr-xxsm css-iii9i8 e1rrn5ka0')]\").text\n",
    "            except NoSuchElementException:\n",
    "                location = np.nan\n",
    "            try:\n",
    "                salary = j.find_element_by_xpath(\".//div[contains(@class, 'css-nq3w9f pr-xxsm')]\").text\n",
    "            except NoSuchElementException:\n",
    "                salary = np.nan\n",
    "            try:\n",
    "                try:\n",
    "                    status = j.find_element_by_xpath(\".//div[contains(@class, 'css-jcbnij eigr9kq1')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    status = j.find_element_by_xpath(\".//div[contains(@class, 'css-65p68w css-m9i057 css-1uov7ef css-crgfuk eigr9kq1')]\").text\n",
    "            except NoSuchElementException:\n",
    "                status = np.nan\n",
    "            try:\n",
    "                post_date_ago = j.find_element_by_xpath(\".//div[contains(@class, 'd-flex align-items-end pl-std css-mi55ob')]\").text\n",
    "            except NoSuchElementException:\n",
    "                post_date_ago = np.nan\n",
    "            try:\n",
    "                job_url = j.find_element_by_xpath(\".//a[contains(@class, 'jobLink css-1rd3saf eigr9kq2')]\").get_attribute(\"href\")\n",
    "            except NoSuchElementException:\n",
    "                job_url = np.nan\n",
    "                \n",
    "\n",
    "            jobs.append({\"Company Rate\" : company_rate,\n",
    "                    \"Company Name\" : company,\n",
    "                    \"Title\" : position,\n",
    "                    \"Location\" : location,\n",
    "                    \"Salary\" : salary,\n",
    "                    \"Staus\" : status,\n",
    "                    \"Post Date\" : post_date_ago,\n",
    "                    \"Job Link\" : job_url})\n",
    "\n",
    "            #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\".//li[contains(@class, 'css-1yshuyv e1gri00l3')]\").click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "                \n",
    "    return pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:37<00:00,  1.30s/it]\n",
      "100%|██████████| 29/29 [00:37<00:00,  1.31s/it]\n",
      "100%|██████████| 30/30 [00:39<00:00,  1.33s/it]\n",
      "100%|██████████| 31/31 [00:44<00:00,  1.43s/it]\n",
      "100%|██████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|██████████| 31/31 [00:45<00:00,  1.46s/it]\n",
      "100%|██████████| 31/31 [00:48<00:00,  1.58s/it]\n",
      "100%|██████████| 31/31 [00:48<00:00,  1.57s/it]\n",
      "100%|██████████| 29/29 [00:44<00:00,  1.52s/it]\n",
      "100%|██████████| 29/29 [00:45<00:00,  1.57s/it]\n",
      "100%|██████████| 29/29 [00:46<00:00,  1.61s/it]\n",
      "100%|██████████| 29/29 [00:54<00:00,  1.87s/it]\n",
      "100%|██████████| 29/29 [00:55<00:00,  1.92s/it]\n",
      "100%|██████████| 29/29 [01:03<00:00,  2.20s/it]\n",
      "100%|██████████| 29/29 [00:55<00:00,  1.90s/it]\n",
      "100%|██████████| 29/29 [00:57<00:00,  1.99s/it]\n",
      "100%|██████████| 29/29 [01:05<00:00,  2.27s/it]\n",
      "100%|██████████| 29/29 [00:58<00:00,  2.03s/it]\n",
      "100%|██████████| 29/29 [01:02<00:00,  2.15s/it]\n",
      "100%|██████████| 29/29 [01:09<00:00,  2.40s/it]\n",
      "100%|██████████| 29/29 [01:06<00:00,  2.28s/it]\n",
      "100%|██████████| 29/29 [01:05<00:00,  2.24s/it]\n",
      "100%|██████████| 29/29 [01:08<00:00,  2.36s/it]\n",
      "100%|██████████| 29/29 [01:10<00:00,  2.42s/it]\n",
      "100%|██████████| 29/29 [01:12<00:00,  2.51s/it]\n",
      "100%|██████████| 29/29 [01:18<00:00,  2.72s/it]\n",
      "100%|██████████| 29/29 [01:20<00:00,  2.78s/it]\n",
      "100%|██████████| 29/29 [01:18<00:00,  2.71s/it]\n",
      "100%|██████████| 29/29 [01:18<00:00,  2.70s/it]\n",
      "100%|██████████| 29/29 [01:24<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping terminated before reaching target number of jobs. Needed 1000, got 911.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Full time with all levels\n",
    "data_scientist = get_jobs('https://www.glassdoor.com/Search/results.htm?keyword=%22data%20scientist%22', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scientist['Post Date'] = data_scientist['Post Date'].apply(lambda x: check_date_h_d(x))\n",
    "data_scientist['Post Date'] = data_scientist['Post Date'].apply(lambda x: transform_days(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_scientist = copy.copy(data_scientist)\n",
    "csv_data_scientist.to_csv('Glassdoor_data_scientist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
